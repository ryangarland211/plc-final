{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Howdy welcome to the final, I'll try to add some fun along the way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, code:int, lexeme:str):\n",
    "        self.code = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self,input:str):\n",
    "        self.input = input\n",
    "        self.token_map = {'a':1,\n",
    "                        'b':2,\n",
    "                        'c':4,\n",
    "                        'd':8,\n",
    "                        'set':9,\n",
    "                        '+':10,\n",
    "                        '-':11,\n",
    "                        '*':12,\n",
    "                        '/':13,\n",
    "                        '%':14,\n",
    "                        '<':15,\n",
    "                        '>':16,\n",
    "                        '<=':17,\n",
    "                        '>=':18,\n",
    "                        '==':19,\n",
    "                        '!=':20,\n",
    "                        '=':21,\n",
    "                        '(':22,\n",
    "                        ')':22,\n",
    "                        '{':23,\n",
    "                        '}':23,\n",
    "                        ';':24,\n",
    "                        'x':25,\n",
    "                        'y':26,\n",
    "                        'z':27,\n",
    "                        'o':28,\n",
    "                        'p':29\n",
    "        \n",
    "        }\n",
    "    def find_tokens(self): \n",
    "        # finds all the tokens in a line\n",
    "        while self.current<len(self.line):\n",
    "            if self.line[self.current] in self.token_map.keys:\n",
    "                self.lexeme = self.line[self.current]\n",
    "                if self.line[self.current] == '>':\n",
    "                    self.eeq()\n",
    "                            \n",
    "                elif self.line[self.current] == '<':\n",
    "                    self.eeq()\n",
    "                            \n",
    "                elif self.line[self.current] == '=':\n",
    "                    self.eeq()\n",
    "                \n",
    "                elif self.line[self.current] == '!':\n",
    "                    self.eeq()\n",
    "                else:\n",
    "                    self.tokens.append(self.token_map[self.lexeme])\n",
    "                    self.inc()\n",
    "            elif self.line[self.current] == 's':\n",
    "                self.setting()\n",
    "            elif self.line[self.current].isnumeric:\n",
    "                self.intHandler()\n",
    "                    \n",
    "            else:\n",
    "                self.error()\n",
    "            self.inc()\n",
    "    def inc(self):\n",
    "        # increments current\n",
    "       self.current+=1\n",
    "    def setting(self):\n",
    "        # checks if the lexume is a assignment\n",
    "        while(self.current <len(self.line)):\n",
    "            if self.lexeme == 'set':\n",
    "                self.inc()\n",
    "                if self.line(self.current) == '':\n",
    "                    self.inc()\n",
    "                    if self.line(self.current) == '`':\n",
    "                        self.inc()\n",
    "                        while self.line(self.current) != '`' and self.current < len(self.line):\n",
    "                           self.inc()\n",
    "                        if self.line(self.current) == '`':\n",
    "                            self.tokens.append(self.token_map[self.lexeme])\n",
    "                        else:\n",
    "                            self.error()\n",
    "            else:\n",
    "                self.inc()\n",
    "                self.lexeme += self.line(self.current)\n",
    "        pass\n",
    "    \n",
    "    def eeq(self):\n",
    "        # Checks to see if the operator is actually comparitive \n",
    "        self.inc()\n",
    "        if self.current <len(self.line):\n",
    "            if self.line(self.current) == '=':\n",
    "                self.lexeme += self.line(self.current)\n",
    "                self.tokens.append(self.token_map[self.lexeme])\n",
    "        else:\n",
    "            self.tokens.append(self.token_map[self.lexeme])\n",
    "        \n",
    "    def intHander(self):\n",
    "        # checks if the ints have a suffix  \n",
    "        while self.lexeme.isnumeric:\n",
    "            self.inc()\n",
    "            self.lexeme+=self.line(self.current)\n",
    "        if self.line(self.current) in self.token_map.keys:\n",
    "            self.tokens.append(self.token_map[self.line(self.current)]) \n",
    "        else:\n",
    "            self.error()\n",
    "            \n",
    "    def error():\n",
    "        # stops the program from running\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self,tokens:list(object)):\n",
    "        self.tokens = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compiler:\n",
    "    def __init__(self, file:str):\n",
    "        self.file = file\n",
    "        text_file = open(file, \"r\")\n",
    "\n",
    "        input = text_file.read()\n",
    "        lex = Lexer(input)\n",
    "        text_file.close\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
